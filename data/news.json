{
  "lastUpdated": "2026-02-18T02:57:37.620Z",
  "items": [
    {
      "title": "Meta&#8217;s new deal with Nvidia buys up millions of AI chips",
      "link": "https://www.theverge.com/ai-artificial-intelligence/880513/nvidia-meta-ai-grace-vera-chips",
      "description": "Meta has struck a multiyear deal to expand its data centers with millions of Nvidia's Grace and Vera CPUs and Blackwell and Rubin GPUs. While Meta has long been using Nvidia's hardware for its AI products, this deal \"represents the first large-scale Nvidia Grace-only deployment,\" which Nvidia says will deliver \"significant performance-per-watt improvements in [Meta's] data centers.\" The deal also includes plans to add Nvidia's next-generation Vera CPUs to Meta's data centers in 2027. \nMeta is also working on its own in-house chips for running AI models, but according to the Financial Times, it has run into \"technical challenges and rollout  …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"An illustration of the Meta logo\" data-caption=\"\" data-portal-copyright=\"Illustration by Nick Barclay / The Verge\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK043_VRG_Illo_N_Barclay_1_Meta-1.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Meta has struck a multiyear deal to expand its data centers with millions of Nvidia's Grace and Vera CPUs and Blackwell and Rubin GPUs. While Meta has long been using Nvidia's hardware for its AI products, this deal \"represents the first large-scale Nvidia Grace-only deployment,\" which <a href=\"https://nvidianews.nvidia.com/news/meta-builds-ai-infrastructure-with-nvidia\">Nvidia says</a> will deliver \"significant performance-per-watt improvements in [Meta's] data centers.\" The deal also includes plans to add Nvidia's next-generation Vera CPUs to Meta's data centers in 2027. </p>\n<p class=\"has-text-align-none\">Meta is also <a href=\"https://www.theverge.com/2024/2/1/24058179/meta-reportedly-working-on-a-new-ai-chip-it-plans-to-launch-this-year\">working on its own in-house chips</a> for running AI models, but according to the <a href=\"https://www.ft.com/content/d3b50dfc-31fa-45a8-9184-c5f0476f4504\"><em>Financial Times</em></a>, it has run into \"technical challenges and rollout  …</p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/880513/nvidia-meta-ai-grace-vera-chips\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Stevie Bonifield",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-18T00:27:08.000Z",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "Google’s AI search results will make links more obvious",
      "link": "https://www.theverge.com/tech/880475/google-ai-overviews-ai-mode-links-update",
      "description": "Google says it will now display links more prominently inside its AI-powered features in Search. Robby Stein, the vice president of Google Search, announced on Tuesday that a list of links will now appear inside a pop-up when you hover over the sources in AI Overviews and AI Mode on desktop, alongside a description of each linked article and accompanying images. \nStein adds that Google will also show these \"more descriptive and prominent link icons\" in its AI responses on desktop and mobile. \"Our testing shows this new UI is more engaging, making it easier to get to great content across the web,\" Stein writes.\nWhile AI Overviews appear as  …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"An illustration of the Google logo on a red, green, and blue background\" data-caption=\"\" data-portal-copyright=\"Image: The Verge\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/STK093_GOOGLE_A-1.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Google says it will now display links more prominently inside its AI-powered features in Search. Robby Stein, the vice president of Google Search, <a href=\"https://x.com/rmstein/status/2023865995908313531?s=20\">announced on Tuesday</a> that a list of links will now appear inside a pop-up when you hover over the sources in AI Overviews and AI Mode on desktop, alongside a description of each linked article and accompanying images. </p>\n<p class=\"has-text-align-none\">Stein adds that Google will also show these \"more descriptive and prominent link icons\" in its AI responses on desktop and mobile. \"Our testing shows this new UI is more engaging, making it easier to get to great content across the web,\" Stein writes.</p>\n<img src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/aimode-link-popup.png?quality=90&amp;strip=all&amp;crop=0,0,100,100\" alt=\"\" title=\"\" data-has-syndication-rights=\"1\" data-caption=\"\" data-portal-copyright=\"Image: Google\">\n<p class=\"has-text-align-none\">While AI Overviews appear as  …</p>\n<p><a href=\"https://www.theverge.com/tech/880475/google-ai-overviews-ai-mode-links-update\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Emma Roth",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T22:38:24.000Z",
      "popularity": 0,
      "category": "ai-hardware"
    },
    {
      "title": "Google announces dates for I/O 2026",
      "link": "https://www.theverge.com/tech/880401/google-io-2026-dates-ai",
      "description": "It's official: Google I/O 2026 will take place from May 19th to 20th. In an announcement on Tuesday, Google says it will share the \"latest AI breakthroughs and updates in products across the company, from Gemini to Android and more\" during the event, which will take place in-person in Mountain View, California's Shoreline Amphitheatre, and online.\nSimilar to previous years, Google I/O 2026 will feature keynotes from company leaders, fireside chats, product demos, and more. Google still hasn't shared the full schedule for its sessions, but the company plans to kick off the event with a keynote on the morning of May 19th. You can also interac …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"An image showing the Google I/O logo\" data-caption=\"\" data-portal-copyright=\"Image: Google\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/google-io-date.png?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">It's official: Google I/O 2026 will take place from May 19th to 20th. In <a href=\"https://blog.google/innovation-and-ai/technology/developers-tools/io-2026-save-the-date/?utm_source=tw&amp;utm_medium=social&amp;utm_campaign=nfg&amp;utm_content=&amp;utm_term=\">an announcement on Tuesday</a>, Google says it will share the \"latest AI breakthroughs and updates in products across the company, from Gemini to Android and more\" during the event, which will take place in-person in Mountain View, California's Shoreline Amphitheatre, <a href=\"https://io.google/2026/\">and online</a>.</p>\n<p class=\"has-text-align-none\">Similar to previous years, Google I/O 2026 will feature keynotes from company leaders, fireside chats, product demos, and more. Google still hasn't shared the full schedule for its sessions, but the company plans to kick off the event with a keynote on the morning of May 19th. You can also interac …</p>\n<p><a href=\"https://www.theverge.com/tech/880401/google-io-2026-dates-ai\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Emma Roth",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T20:56:56.000Z",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "Meta and Other Tech Firms Put Restrictions on Use of OpenClaw Over Security Fears",
      "link": "https://www.wired.com/story/openclaw-banned-by-tech-companies-as-security-concerns-mount/",
      "description": "Security experts have urged people to be cautious with the viral agentic AI tool, known for being highly capable but also wildly unpredictable.",
      "content": "Security experts have urged people to be cautious with the viral agentic AI tool, known for being highly capable but also wildly unpredictable.",
      "author": "Paresh Dave",
      "source": "Wired AI",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 20:10:12 +0000",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "Apple is reportedly planning to launch AI-powered glasses, a pendant, and AirPods",
      "link": "https://www.theverge.com/tech/880293/apple-ai-hardware-smart-glasses-pin-airpods",
      "description": "The second-gen Ray-Ban Meta smart glasses. | Photo by Amelia Holowaty Krales / The Verge\t\n\nApple is pushing ahead with plans to launch its first pair of smart glasses, along with an AI-powered pendant and camera-equipped AirPods, according to a report from Bloomberg's Mark Gurman. The three devices come with built-in cameras and will connect to the iPhone, allowing Siri to use \"visual context to carry out actions,\" Bloomberg reports.\nApple is reportedly aiming to start production of its smart glasses in December, ahead of a 2027 launch. The new device will compete directly with Meta's lineup of smart glasses and is rumored to feature speakers, microphones, and a high-resolution camera for taking photos and videos, in addition to  …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"A photo of the second-gen Ray-Ban Meta smart glasses\" data-caption=\"The second-gen Ray-Ban Meta smart glasses. | Photo by Amelia Holowaty Krales / The Verge\" data-portal-copyright=\"Photo by Amelia Holowaty Krales / The Verge\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/257979_RayBan_Meta_Gen2_AKrales_0103.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tThe second-gen Ray-Ban Meta smart glasses. | Photo by Amelia Holowaty Krales / The Verge\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Apple is pushing ahead with plans to launch its first pair of smart glasses, along with an AI-powered pendant and camera-equipped AirPods, <a href=\"https://www.bloomberg.com/news/articles/2026-02-17/apple-ramps-up-work-on-glasses-pendant-and-camera-airpods-for-ai-era\">according to a report from <em>Bloomberg</em>'s Mark Gurman</a>. The three devices come with built-in cameras and will connect to the iPhone, allowing Siri to use \"visual context to carry out actions,\" <em>Bloomberg</em> reports.</p>\n<p class=\"has-text-align-none\">Apple is reportedly aiming to start production of its smart glasses in December, ahead of a 2027 launch. The new device will compete directly with Meta's lineup of smart glasses and is rumored to feature speakers, microphones, and a high-resolution camera for taking photos and videos, in addition to  …</p>\n<p><a href=\"https://www.theverge.com/tech/880293/apple-ai-hardware-smart-glasses-pin-airpods\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Emma Roth",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T19:26:21.000Z",
      "popularity": 0,
      "category": "ai-hardware"
    },
    {
      "title": "WordPress’ new AI assistant will let users edit their sites with prompts",
      "link": "https://www.theverge.com/tech/880223/wordpress-launches-ai-assistant",
      "description": "Starting on Tuesday, WordPress users can edit their websites using the new AI assistant built into the platform's site editor and media library, TechCrunch reports. The AI has a sidebar in the WordPress site editor where users can ask it to edit and translate text, generate and edit images using Google's Nano Banana, and make adjustments to their sites like creating new pages or changing fonts.\n\nUsers can also interact with the AI through the new block notes feature WordPress added in its 6.9 update in December, which allows users to leave comments in the site editor. By tagging the AI assistant with \"@ai\" in block notes, users can give it p …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"A screenshot of WordPress’ built-in AI assistant in the site editor\" data-caption=\"\" data-portal-copyright=\"Image: WordPress\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/wordpress-ai-assistant-page-editor.png?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Starting on Tuesday, WordPress users can edit their websites using the <a href=\"https://wordpress.com/blog/2026/02/17/wordpress-ai-assistant/\">new AI assistant</a> built into the platform's site editor and media library, <a href=\"https://techcrunch.com/2026/02/17/wordpress-com-adds-an-ai-assistant-that-can-edit-adjust-styles-create-images-and-more/\"><em>TechCrunch</em></a> reports. The AI has a sidebar in the WordPress site editor where users can ask it to edit and translate text, generate and edit images using Google's Nano Banana, and make adjustments to their sites like creating new pages or changing fonts.</p>\n<div class=\"youtube-embed\"><iframe title=\"WordPress.com Just Got Its Own AI Assistant\" src=\"https://www.youtube.com/embed/olHAZ7ao7_0?rel=0\" allowfullscreen allow=\"accelerometer *; clipboard-write *; encrypted-media *; gyroscope *; picture-in-picture *; web-share *;\"></iframe></div>\n<p class=\"has-text-align-none\">Users can also interact with the AI through the new <a href=\"https://wordpress.org/download/releases/6-9/\">block notes feature</a> WordPress added in its 6.9 update in December, which allows users to leave comments in the site editor. By tagging the AI assistant with \"@ai\" in block notes, users can give it p …</p>\n<p><a href=\"https://www.theverge.com/tech/880223/wordpress-launches-ai-assistant\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Stevie Bonifield",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T18:33:15.000Z",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "The Download: the rise of luxury car theft, and fighting antimicrobial resistance",
      "link": "https://www.technologyreview.com/2026/02/17/1133018/the-download-the-rise-of-luxury-car-theft-and-fighting-antimicrobial-resistance/",
      "description": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. The curious case of the disappearing Lamborghinis Across the world, unsuspecting people are unwittingly becoming caught up in a new and growing type of organized criminal enterprise: vehicle transport fraud and theft. Crooks…",
      "content": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. The curious case of the disappearing Lamborghinis Across the world, unsuspecting people are unwittingly becoming caught up in a new and growing type of organized criminal enterprise: vehicle transport fraud and theft. Crooks&#8230;",
      "author": "Rhiannon Williams",
      "source": "MIT Tech Review",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 13:10:00 +0000",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "Laurie Spiegel on the difference between algorithmic music and ‘AI’",
      "link": "https://www.theverge.com/report/879819/laurie-spiegel-is-celebrating-40-of-music-mouse-with-a-modern-revival",
      "description": "From Bell Labs to Macs, Laurie Spiegel has pushed musical boundaries. | Image: Irina Prosser / Eventide\t\n\nIn 1986, electronic music pioneer Laurie Spiegel created Music Mouse, a way for those with a Mac, Atari, or Amiga computer to dabble in algorithmic music creation. Music Mouse is deceptively simple: Notes are arranged on an XY grid, and you play it by moving a mouse around. Back in 1986, the computer mouse was still a relatively novel device. While it can trace its origins back to the late '60s, it wasn't until the Macintosh 128K in 1984 that it started seeing widespread adoption.\nBy then Spiegel, was already an accomplished composer. Her 1980 album The Expanding Universe is generally considered among the greatest ambient records of all tim …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"Laurie Spiegel on the streets of NYC.\" data-caption=\"From Bell Labs to Macs, Laurie Spiegel has pushed musical boundaries. | Image: Irina Prosser / Eventide\" data-portal-copyright=\"Image: Irina Prosser / Eventide\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/04-Laurie-Spiegel-by-Irina-Prosser.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tFrom Bell Labs to Macs, Laurie Spiegel has pushed musical boundaries. | Image: Irina Prosser / Eventide\t</figcaption>\n</figure>\n<p class=\"has-drop-cap has-text-align-none\">In 1986, electronic music pioneer Laurie Spiegel created <a href=\"https://youtu.be/D-mmEvGOopk\">Music Mouse</a>, a way for those with a Mac, Atari, or Amiga computer to dabble in algorithmic music creation. <a href=\"https://www.eventideaudio.com/software/music-mouse/\">Music Mouse</a> is deceptively simple: Notes are arranged on an XY grid, and you play it by moving a mouse around. Back in 1986, the computer mouse was still a relatively novel device. While it can trace its origins back to the late '60s, it wasn't until the <a href=\"https://en.wikipedia.org/wiki/Macintosh_128K\">Macintosh 128K</a> in 1984 that it started seeing widespread adoption.</p>\n<p class=\"has-text-align-none\">By then Spiegel, was already an accomplished composer. Her 1980 album <a href=\"https://lauriespiegel.bandcamp.com/album/the-expanding-universe?search_item_id%3D1696851893%26search_item_type%3Da%26search_match_part%3D%253F%26search_page_id%3D5139357610%26search_page_no%3D0%26search_rank%3D2=\"><em>The Expanding Universe</em></a> is generally considered among the <a href=\"https://pitchfork.com/features/lists-and-guides/9948-the-50-best-ambient-albums-of-all-time/\">greatest ambient</a> records of all tim …</p>\n<p><a href=\"https://www.theverge.com/report/879819/laurie-spiegel-is-celebrating-40-of-music-mouse-with-a-modern-revival\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Terrence O’Brien",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T13:00:00.000Z",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "The Small English Town Swept Up in the Global AI Arms Race",
      "link": "https://www.wired.com/story/the-small-english-town-swept-up-in-the-global-ai-arms-race/",
      "description": "The residents of Potters Bar are working to protect the “greenbelt” of farms, forests, and meadows that surround London from the endless demand for AI infrastructure.",
      "content": "The residents of Potters Bar are working to protect the “greenbelt” of farms, forests, and meadows that surround London from the endless demand for AI infrastructure.",
      "author": "Joel Khalili",
      "source": "Wired AI",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 07:00:00 +0000",
      "popularity": 0,
      "category": "ai-hardware"
    },
    {
      "title": "When to Think Fast and Slow? AMOR: Entropy-Based Metacognitive Gate for Dynamic SSM-Attention Switching",
      "link": "https://arxiv.org/abs/2602.13215",
      "description": "arXiv:2602.13215v1 Announce Type: new \nAbstract: Transformers allocate uniform computation to every position, regardless of difficulty. State Space Models (SSMs) offer efficient alternatives but struggle with precise information retrieval over a long horizon. Inspired by dual-process theories of cognition (Kahneman, 2011), we propose AMOR (Adaptive Metacognitive Output Router), a hybrid architecture that dynamically engages sparse attention only when an SSM backbone is \"uncertain\"--as measured by prediction entropy. Compared to standard transformers, AMOR gains efficiency by projecting keys and values from SSM hidden states (Ghost KV), reusing the SSM's O(n) computation rather than requiring O(n^2) attention at every layer. On small-scale synthetic retrieval tasks, AMOR outperforms both SSM-only and transformer-only baselines, achieving perfect retrieval accuracy while engaging attention on only 22% of positions. We validate that prediction entropy reliably signals retrieval need, with a gap of 1.09 nats (nearly half the entropy range) between retrieval and local positions. Additionally, our approach provides interpretable adaptive computation, where routing decisions can be understood in information-theoretic terms.",
      "content": "arXiv:2602.13215v1 Announce Type: new \nAbstract: Transformers allocate uniform computation to every position, regardless of difficulty. State Space Models (SSMs) offer efficient alternatives but struggle with precise information retrieval over a long horizon. Inspired by dual-process theories of cognition (Kahneman, 2011), we propose AMOR (Adaptive Metacognitive Output Router), a hybrid architecture that dynamically engages sparse attention only when an SSM backbone is \"uncertain\"--as measured by prediction entropy. Compared to standard transformers, AMOR gains efficiency by projecting keys and values from SSM hidden states (Ghost KV), reusing the SSM's O(n) computation rather than requiring O(n^2) attention at every layer. On small-scale synthetic retrieval tasks, AMOR outperforms both SSM-only and transformer-only baselines, achieving perfect retrieval accuracy while engaging attention on only 22% of positions. We validate that prediction entropy reliably signals retrieval need, with a gap of 1.09 nats (nearly half the entropy range) between retrieval and local positions. Additionally, our approach provides interpretable adaptive computation, where routing decisions can be understood in information-theoretic terms.",
      "author": "Haoran Zheng",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "PlotChain: Deterministic Checkpointed Evaluation of Multimodal LLMs on Engineering Plot Reading",
      "link": "https://arxiv.org/abs/2602.13232",
      "description": "arXiv:2602.13232v1 Announce Type: new \nAbstract: We present PlotChain, a deterministic, generator-based benchmark for evaluating multimodal large language models (MLLMs) on engineering plot reading-recovering quantitative values from classic plots (e.g., Bode/FFT, step response, stress-strain, pump curves) rather than OCR-only extraction or free-form captioning. PlotChain contains 15 plot families with 450 rendered plots (30 per family), where every item is produced from known parameters and paired with exact ground truth computed directly from the generating process. A central contribution is checkpoint-based diagnostic evaluation: in addition to final targets, each item includes intermediate 'cp_' fields that isolate sub-skills (e.g., reading cutoff frequency or peak magnitude) and enable failure localization within a plot family. We evaluate four state-of-the-art MLLMs under a standardized, deterministic protocol (temperature = 0 and a strict JSON-only numeric output schema) and score predictions using per-field tolerances designed to reflect human plot-reading precision. Under the 'plotread' tolerance policy, the top models achieve 80.42% (Gemini 2.5 Pro), 79.84% (GPT-4.1), and 78.21% (Claude Sonnet 4.5) overall field-level pass rates, while GPT-4o trails at 61.59%. Despite strong performance on many families, frequency-domain tasks remain brittle: bandpass response stays low (<= 23%), and FFT spectrum remains challenging. We release the generator, dataset, raw model outputs, scoring code, and manifests with checksums to support fully reproducible runs and retrospective rescoring under alternative tolerance policies.",
      "content": "arXiv:2602.13232v1 Announce Type: new \nAbstract: We present PlotChain, a deterministic, generator-based benchmark for evaluating multimodal large language models (MLLMs) on engineering plot reading-recovering quantitative values from classic plots (e.g., Bode/FFT, step response, stress-strain, pump curves) rather than OCR-only extraction or free-form captioning. PlotChain contains 15 plot families with 450 rendered plots (30 per family), where every item is produced from known parameters and paired with exact ground truth computed directly from the generating process. A central contribution is checkpoint-based diagnostic evaluation: in addition to final targets, each item includes intermediate 'cp_' fields that isolate sub-skills (e.g., reading cutoff frequency or peak magnitude) and enable failure localization within a plot family. We evaluate four state-of-the-art MLLMs under a standardized, deterministic protocol (temperature = 0 and a strict JSON-only numeric output schema) and score predictions using per-field tolerances designed to reflect human plot-reading precision. Under the 'plotread' tolerance policy, the top models achieve 80.42% (Gemini 2.5 Pro), 79.84% (GPT-4.1), and 78.21% (Claude Sonnet 4.5) overall field-level pass rates, while GPT-4o trails at 61.59%. Despite strong performance on many families, frequency-domain tasks remain brittle: bandpass response stays low (<= 23%), and FFT spectrum remains challenging. We release the generator, dataset, raw model outputs, scoring code, and manifests with checksums to support fully reproducible runs and retrospective rescoring under alternative tolerance policies.",
      "author": "Mayank Ravishankara",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "Accuracy Standards for AI at Work vs. Personal Life: Evidence from an Online Survey",
      "link": "https://arxiv.org/abs/2602.13283",
      "description": "arXiv:2602.13283v1 Announce Type: new \nAbstract: We study how people trade off accuracy when using AI-powered tools in professional versus personal contexts for adoption purposes, the determinants of those trade-offs, and how users cope when AI/apps are unavailable. Because modern AI systems (especially generative models) can produce acceptable but non-identical outputs, we define \"accuracy\" as context-specific reliability: the degree to which an output aligns with the user's intent within a tolerance threshold that depends on stakes and the cost of correction. In an online survey (N=300), among respondents with both accuracy items (N=170), the share requiring high accuracy (top-box) is 24.1% at work vs. 8.8% in personal life (+15.3 pp; z=6.29, p<0.001). The gap remains large under a broader top-two-box definition (67.0% vs. 32.9%) and on the full 1-5 ordinal scale (mean 3.86 vs. 3.08). Heavy app use and experience patterns correlate with stricter work standards (H2). When tools are unavailable (H3), respondents report more disruption in personal routines than at work (34.1% vs. 15.3%, p<0.01). We keep the main text focused on these substantive results and place test taxonomy and power derivations in a technical appendix.",
      "content": "arXiv:2602.13283v1 Announce Type: new \nAbstract: We study how people trade off accuracy when using AI-powered tools in professional versus personal contexts for adoption purposes, the determinants of those trade-offs, and how users cope when AI/apps are unavailable. Because modern AI systems (especially generative models) can produce acceptable but non-identical outputs, we define \"accuracy\" as context-specific reliability: the degree to which an output aligns with the user's intent within a tolerance threshold that depends on stakes and the cost of correction. In an online survey (N=300), among respondents with both accuracy items (N=170), the share requiring high accuracy (top-box) is 24.1% at work vs. 8.8% in personal life (+15.3 pp; z=6.29, p<0.001). The gap remains large under a broader top-two-box definition (67.0% vs. 32.9%) and on the full 1-5 ordinal scale (mean 3.86 vs. 3.08). Heavy app use and experience patterns correlate with stricter work standards (H2). When tools are unavailable (H3), respondents report more disruption in personal routines than at work (34.1% vs. 15.3%, p<0.01). We keep the main text focused on these substantive results and place test taxonomy and power derivations in a technical appendix.",
      "author": "Gaston Besanson, Federico Todeschini",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "On-Policy Supervised Fine-Tuning for Efficient Reasoning",
      "link": "https://arxiv.org/abs/2602.13407",
      "description": "arXiv:2602.13407v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) are commonly trained with reinforcement learning (RL) to explore long chain-of-thought reasoning, achieving strong performance at high computational cost. Recent methods add multi-reward objectives to jointly optimize correctness and brevity, but these complex extensions often destabilize training and yield suboptimal trade-offs. We revisit this objective and challenge the necessity of such complexity. Through principled analysis, we identify fundamental misalignments in this paradigm: KL regularization loses its intended role when correctness and length are directly verifiable, and group-wise normalization becomes ambiguous under multiple reward signals. By removing these two items and simplifying the reward to a truncation-based length penalty, we show that the optimization problem reduces to supervised fine-tuning on self-generated data filtered for both correctness and conciseness. We term this simplified training strategy on-policy SFT. Despite its simplicity, on-policy SFT consistently defines the accuracy-efficiency Pareto frontier. It reduces CoT length by up to 80 while maintaining original accuracy, surpassing more complex RL-based methods across five benchmarks. Furthermore, it significantly enhances training efficiency, reducing GPU memory usage by 50% and accelerating convergence by 70%. Our code is available at https://github.com/EIT-NLP/On-Policy-SFT.",
      "content": "arXiv:2602.13407v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) are commonly trained with reinforcement learning (RL) to explore long chain-of-thought reasoning, achieving strong performance at high computational cost. Recent methods add multi-reward objectives to jointly optimize correctness and brevity, but these complex extensions often destabilize training and yield suboptimal trade-offs. We revisit this objective and challenge the necessity of such complexity. Through principled analysis, we identify fundamental misalignments in this paradigm: KL regularization loses its intended role when correctness and length are directly verifiable, and group-wise normalization becomes ambiguous under multiple reward signals. By removing these two items and simplifying the reward to a truncation-based length penalty, we show that the optimization problem reduces to supervised fine-tuning on self-generated data filtered for both correctness and conciseness. We term this simplified training strategy on-policy SFT. Despite its simplicity, on-policy SFT consistently defines the accuracy-efficiency Pareto frontier. It reduces CoT length by up to 80 while maintaining original accuracy, surpassing more complex RL-based methods across five benchmarks. Furthermore, it significantly enhances training efficiency, reducing GPU memory usage by 50% and accelerating convergence by 70%. Our code is available at https://github.com/EIT-NLP/On-Policy-SFT.",
      "author": "Anhao Zhao, Ziyang Chen, Junlong Tong, Yingqi Fan, Fanghua Ye, Shuhao Li, Yunpu Ma, Wenjie Li, Xiaoyu Shen",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "BotzoneBench: Scalable LLM Evaluation via Graded AI Anchors",
      "link": "https://arxiv.org/abs/2602.13214",
      "description": "arXiv:2602.13214v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly deployed in interactive environments requiring strategic decision-making, yet systematic evaluation of these capabilities remains challenging. Existing benchmarks for LLMs primarily assess static reasoning through isolated tasks and fail to capture dynamic strategic abilities. Recent game-based evaluations employ LLM-vs-LLM tournaments that produce relative rankings dependent on transient model pools, incurring quadratic computational costs and lacking stable performance anchors for longitudinal tracking. The central challenge is establishing a scalable evaluation framework that measures LLM strategic reasoning against consistent, interpretable standards rather than volatile peer models. Here we show that anchoring LLM evaluation to fixed hierarchies of skill-calibrated game Artificial Intelligence (AI) enables linear-time absolute skill measurement with stable cross-temporal interpretability. Built on the Botzone platform's established competitive infrastructure, our BotzoneBench evaluates LLMs across eight diverse games spanning deterministic perfect-information board games to stochastic imperfect-information card games. Through systematic assessment of 177,047 state-action pairs from five flagship models, we reveal significant performance disparities and identify distinct strategic behaviors, with top-performing models achieving proficiency comparable to mid-to-high-tier specialized game AI in multiple domains. This anchored evaluation paradigm generalizes beyond games to any domain with well-defined skill hierarchies, establishing a scalable and reusable framework for assessing interactive AI capabilities.",
      "content": "arXiv:2602.13214v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly deployed in interactive environments requiring strategic decision-making, yet systematic evaluation of these capabilities remains challenging. Existing benchmarks for LLMs primarily assess static reasoning through isolated tasks and fail to capture dynamic strategic abilities. Recent game-based evaluations employ LLM-vs-LLM tournaments that produce relative rankings dependent on transient model pools, incurring quadratic computational costs and lacking stable performance anchors for longitudinal tracking. The central challenge is establishing a scalable evaluation framework that measures LLM strategic reasoning against consistent, interpretable standards rather than volatile peer models. Here we show that anchoring LLM evaluation to fixed hierarchies of skill-calibrated game Artificial Intelligence (AI) enables linear-time absolute skill measurement with stable cross-temporal interpretability. Built on the Botzone platform's established competitive infrastructure, our BotzoneBench evaluates LLMs across eight diverse games spanning deterministic perfect-information board games to stochastic imperfect-information card games. Through systematic assessment of 177,047 state-action pairs from five flagship models, we reveal significant performance disparities and identify distinct strategic behaviors, with top-performing models achieving proficiency comparable to mid-to-high-tier specialized game AI in multiple domains. This anchored evaluation paradigm generalizes beyond games to any domain with well-defined skill hierarchies, establishing a scalable and reusable framework for assessing interactive AI capabilities.",
      "author": "Lingfeng Li, Yunlong Lu, Yuefei Zhang, Jingyu Yao, Yixin Zhu, KeYuan Cheng, Yongyi Wang, Qirui Zheng, Xionghui Yang, Wenxin Li",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-hardware"
    },
    {
      "title": "MAPLE: A Sub-Agent Architecture for Memory, Learning, and Personalization in Agentic AI Systems",
      "link": "https://arxiv.org/abs/2602.13258",
      "description": "arXiv:2602.13258v1 Announce Type: new \nAbstract: Large language model (LLM) agents have emerged as powerful tools for complex tasks, yet their ability to adapt to individual users remains fundamentally limited. We argue this limitation stems from a critical architectural conflation: current systems treat memory, learning, and personalization as a unified capability rather than three distinct mechanisms requiring different infrastructure, operating on different timescales, and benefiting from independent optimization. We propose MAPLE (Memory-Adaptive Personalized LEarning), a principled decomposition where Memory handles storage and retrieval infrastructure; Learning extracts intelligence from accumulated interactions asynchronously; and Personalization applies learned knowledge in real-time within finite context budgets. Each component operates as a dedicated sub-agent with specialized tooling and well-defined interfaces. Experimental evaluation on the MAPLE-Personas benchmark demonstrates that our decomposition achieves a 14.6% improvement in personalization score compared to a stateless baseline (p < 0.01, Cohen's d = 0.95) and increases trait incorporation rate from 45% to 75% -- enabling agents that genuinely learn and adapt.",
      "content": "arXiv:2602.13258v1 Announce Type: new \nAbstract: Large language model (LLM) agents have emerged as powerful tools for complex tasks, yet their ability to adapt to individual users remains fundamentally limited. We argue this limitation stems from a critical architectural conflation: current systems treat memory, learning, and personalization as a unified capability rather than three distinct mechanisms requiring different infrastructure, operating on different timescales, and benefiting from independent optimization. We propose MAPLE (Memory-Adaptive Personalized LEarning), a principled decomposition where Memory handles storage and retrieval infrastructure; Learning extracts intelligence from accumulated interactions asynchronously; and Personalization applies learned knowledge in real-time within finite context budgets. Each component operates as a dedicated sub-agent with specialized tooling and well-defined interfaces. Experimental evaluation on the MAPLE-Personas benchmark demonstrates that our decomposition achieves a 14.6% improvement in personalization score compared to a stateless baseline (p < 0.01, Cohen's d = 0.95) and increases trait incorporation rate from 45% to 75% -- enabling agents that genuinely learn and adapt.",
      "author": "Deepak Babu Piskala",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-hardware"
    }
  ],
  "history": [
    {
      "title": "Meta&#8217;s new deal with Nvidia buys up millions of AI chips",
      "link": "https://www.theverge.com/ai-artificial-intelligence/880513/nvidia-meta-ai-grace-vera-chips",
      "description": "Meta has struck a multiyear deal to expand its data centers with millions of Nvidia's Grace and Vera CPUs and Blackwell and Rubin GPUs. While Meta has long been using Nvidia's hardware for its AI products, this deal \"represents the first large-scale Nvidia Grace-only deployment,\" which Nvidia says will deliver \"significant performance-per-watt improvements in [Meta's] data centers.\" The deal also includes plans to add Nvidia's next-generation Vera CPUs to Meta's data centers in 2027. \nMeta is also working on its own in-house chips for running AI models, but according to the Financial Times, it has run into \"technical challenges and rollout  …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"An illustration of the Meta logo\" data-caption=\"\" data-portal-copyright=\"Illustration by Nick Barclay / The Verge\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK043_VRG_Illo_N_Barclay_1_Meta-1.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Meta has struck a multiyear deal to expand its data centers with millions of Nvidia's Grace and Vera CPUs and Blackwell and Rubin GPUs. While Meta has long been using Nvidia's hardware for its AI products, this deal \"represents the first large-scale Nvidia Grace-only deployment,\" which <a href=\"https://nvidianews.nvidia.com/news/meta-builds-ai-infrastructure-with-nvidia\">Nvidia says</a> will deliver \"significant performance-per-watt improvements in [Meta's] data centers.\" The deal also includes plans to add Nvidia's next-generation Vera CPUs to Meta's data centers in 2027. </p>\n<p class=\"has-text-align-none\">Meta is also <a href=\"https://www.theverge.com/2024/2/1/24058179/meta-reportedly-working-on-a-new-ai-chip-it-plans-to-launch-this-year\">working on its own in-house chips</a> for running AI models, but according to the <a href=\"https://www.ft.com/content/d3b50dfc-31fa-45a8-9184-c5f0476f4504\"><em>Financial Times</em></a>, it has run into \"technical challenges and rollout  …</p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/880513/nvidia-meta-ai-grace-vera-chips\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Stevie Bonifield",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-18T00:27:08.000Z",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "Google’s AI search results will make links more obvious",
      "link": "https://www.theverge.com/tech/880475/google-ai-overviews-ai-mode-links-update",
      "description": "Google says it will now display links more prominently inside its AI-powered features in Search. Robby Stein, the vice president of Google Search, announced on Tuesday that a list of links will now appear inside a pop-up when you hover over the sources in AI Overviews and AI Mode on desktop, alongside a description of each linked article and accompanying images. \nStein adds that Google will also show these \"more descriptive and prominent link icons\" in its AI responses on desktop and mobile. \"Our testing shows this new UI is more engaging, making it easier to get to great content across the web,\" Stein writes.\nWhile AI Overviews appear as  …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"An illustration of the Google logo on a red, green, and blue background\" data-caption=\"\" data-portal-copyright=\"Image: The Verge\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/STK093_GOOGLE_A-1.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Google says it will now display links more prominently inside its AI-powered features in Search. Robby Stein, the vice president of Google Search, <a href=\"https://x.com/rmstein/status/2023865995908313531?s=20\">announced on Tuesday</a> that a list of links will now appear inside a pop-up when you hover over the sources in AI Overviews and AI Mode on desktop, alongside a description of each linked article and accompanying images. </p>\n<p class=\"has-text-align-none\">Stein adds that Google will also show these \"more descriptive and prominent link icons\" in its AI responses on desktop and mobile. \"Our testing shows this new UI is more engaging, making it easier to get to great content across the web,\" Stein writes.</p>\n<img src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/aimode-link-popup.png?quality=90&amp;strip=all&amp;crop=0,0,100,100\" alt=\"\" title=\"\" data-has-syndication-rights=\"1\" data-caption=\"\" data-portal-copyright=\"Image: Google\">\n<p class=\"has-text-align-none\">While AI Overviews appear as  …</p>\n<p><a href=\"https://www.theverge.com/tech/880475/google-ai-overviews-ai-mode-links-update\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Emma Roth",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T22:38:24.000Z",
      "popularity": 0,
      "category": "ai-hardware"
    },
    {
      "title": "Google announces dates for I/O 2026",
      "link": "https://www.theverge.com/tech/880401/google-io-2026-dates-ai",
      "description": "It's official: Google I/O 2026 will take place from May 19th to 20th. In an announcement on Tuesday, Google says it will share the \"latest AI breakthroughs and updates in products across the company, from Gemini to Android and more\" during the event, which will take place in-person in Mountain View, California's Shoreline Amphitheatre, and online.\nSimilar to previous years, Google I/O 2026 will feature keynotes from company leaders, fireside chats, product demos, and more. Google still hasn't shared the full schedule for its sessions, but the company plans to kick off the event with a keynote on the morning of May 19th. You can also interac …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"An image showing the Google I/O logo\" data-caption=\"\" data-portal-copyright=\"Image: Google\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/google-io-date.png?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">It's official: Google I/O 2026 will take place from May 19th to 20th. In <a href=\"https://blog.google/innovation-and-ai/technology/developers-tools/io-2026-save-the-date/?utm_source=tw&amp;utm_medium=social&amp;utm_campaign=nfg&amp;utm_content=&amp;utm_term=\">an announcement on Tuesday</a>, Google says it will share the \"latest AI breakthroughs and updates in products across the company, from Gemini to Android and more\" during the event, which will take place in-person in Mountain View, California's Shoreline Amphitheatre, <a href=\"https://io.google/2026/\">and online</a>.</p>\n<p class=\"has-text-align-none\">Similar to previous years, Google I/O 2026 will feature keynotes from company leaders, fireside chats, product demos, and more. Google still hasn't shared the full schedule for its sessions, but the company plans to kick off the event with a keynote on the morning of May 19th. You can also interac …</p>\n<p><a href=\"https://www.theverge.com/tech/880401/google-io-2026-dates-ai\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Emma Roth",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T20:56:56.000Z",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "Meta and Other Tech Firms Put Restrictions on Use of OpenClaw Over Security Fears",
      "link": "https://www.wired.com/story/openclaw-banned-by-tech-companies-as-security-concerns-mount/",
      "description": "Security experts have urged people to be cautious with the viral agentic AI tool, known for being highly capable but also wildly unpredictable.",
      "content": "Security experts have urged people to be cautious with the viral agentic AI tool, known for being highly capable but also wildly unpredictable.",
      "author": "Paresh Dave",
      "source": "Wired AI",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 20:10:12 +0000",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "Apple is reportedly planning to launch AI-powered glasses, a pendant, and AirPods",
      "link": "https://www.theverge.com/tech/880293/apple-ai-hardware-smart-glasses-pin-airpods",
      "description": "The second-gen Ray-Ban Meta smart glasses. | Photo by Amelia Holowaty Krales / The Verge\t\n\nApple is pushing ahead with plans to launch its first pair of smart glasses, along with an AI-powered pendant and camera-equipped AirPods, according to a report from Bloomberg's Mark Gurman. The three devices come with built-in cameras and will connect to the iPhone, allowing Siri to use \"visual context to carry out actions,\" Bloomberg reports.\nApple is reportedly aiming to start production of its smart glasses in December, ahead of a 2027 launch. The new device will compete directly with Meta's lineup of smart glasses and is rumored to feature speakers, microphones, and a high-resolution camera for taking photos and videos, in addition to  …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"A photo of the second-gen Ray-Ban Meta smart glasses\" data-caption=\"The second-gen Ray-Ban Meta smart glasses. | Photo by Amelia Holowaty Krales / The Verge\" data-portal-copyright=\"Photo by Amelia Holowaty Krales / The Verge\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/257979_RayBan_Meta_Gen2_AKrales_0103.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tThe second-gen Ray-Ban Meta smart glasses. | Photo by Amelia Holowaty Krales / The Verge\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Apple is pushing ahead with plans to launch its first pair of smart glasses, along with an AI-powered pendant and camera-equipped AirPods, <a href=\"https://www.bloomberg.com/news/articles/2026-02-17/apple-ramps-up-work-on-glasses-pendant-and-camera-airpods-for-ai-era\">according to a report from <em>Bloomberg</em>'s Mark Gurman</a>. The three devices come with built-in cameras and will connect to the iPhone, allowing Siri to use \"visual context to carry out actions,\" <em>Bloomberg</em> reports.</p>\n<p class=\"has-text-align-none\">Apple is reportedly aiming to start production of its smart glasses in December, ahead of a 2027 launch. The new device will compete directly with Meta's lineup of smart glasses and is rumored to feature speakers, microphones, and a high-resolution camera for taking photos and videos, in addition to  …</p>\n<p><a href=\"https://www.theverge.com/tech/880293/apple-ai-hardware-smart-glasses-pin-airpods\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Emma Roth",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T19:26:21.000Z",
      "popularity": 0,
      "category": "ai-hardware"
    },
    {
      "title": "WordPress’ new AI assistant will let users edit their sites with prompts",
      "link": "https://www.theverge.com/tech/880223/wordpress-launches-ai-assistant",
      "description": "Starting on Tuesday, WordPress users can edit their websites using the new AI assistant built into the platform's site editor and media library, TechCrunch reports. The AI has a sidebar in the WordPress site editor where users can ask it to edit and translate text, generate and edit images using Google's Nano Banana, and make adjustments to their sites like creating new pages or changing fonts.\n\nUsers can also interact with the AI through the new block notes feature WordPress added in its 6.9 update in December, which allows users to leave comments in the site editor. By tagging the AI assistant with \"@ai\" in block notes, users can give it p …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"A screenshot of WordPress’ built-in AI assistant in the site editor\" data-caption=\"\" data-portal-copyright=\"Image: WordPress\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/wordpress-ai-assistant-page-editor.png?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Starting on Tuesday, WordPress users can edit their websites using the <a href=\"https://wordpress.com/blog/2026/02/17/wordpress-ai-assistant/\">new AI assistant</a> built into the platform's site editor and media library, <a href=\"https://techcrunch.com/2026/02/17/wordpress-com-adds-an-ai-assistant-that-can-edit-adjust-styles-create-images-and-more/\"><em>TechCrunch</em></a> reports. The AI has a sidebar in the WordPress site editor where users can ask it to edit and translate text, generate and edit images using Google's Nano Banana, and make adjustments to their sites like creating new pages or changing fonts.</p>\n<div class=\"youtube-embed\"><iframe title=\"WordPress.com Just Got Its Own AI Assistant\" src=\"https://www.youtube.com/embed/olHAZ7ao7_0?rel=0\" allowfullscreen allow=\"accelerometer *; clipboard-write *; encrypted-media *; gyroscope *; picture-in-picture *; web-share *;\"></iframe></div>\n<p class=\"has-text-align-none\">Users can also interact with the AI through the new <a href=\"https://wordpress.org/download/releases/6-9/\">block notes feature</a> WordPress added in its 6.9 update in December, which allows users to leave comments in the site editor. By tagging the AI assistant with \"@ai\" in block notes, users can give it p …</p>\n<p><a href=\"https://www.theverge.com/tech/880223/wordpress-launches-ai-assistant\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Stevie Bonifield",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T18:33:15.000Z",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "The Download: the rise of luxury car theft, and fighting antimicrobial resistance",
      "link": "https://www.technologyreview.com/2026/02/17/1133018/the-download-the-rise-of-luxury-car-theft-and-fighting-antimicrobial-resistance/",
      "description": "This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. The curious case of the disappearing Lamborghinis Across the world, unsuspecting people are unwittingly becoming caught up in a new and growing type of organized criminal enterprise: vehicle transport fraud and theft. Crooks…",
      "content": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. The curious case of the disappearing Lamborghinis Across the world, unsuspecting people are unwittingly becoming caught up in a new and growing type of organized criminal enterprise: vehicle transport fraud and theft. Crooks&#8230;",
      "author": "Rhiannon Williams",
      "source": "MIT Tech Review",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 13:10:00 +0000",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "Laurie Spiegel on the difference between algorithmic music and ‘AI’",
      "link": "https://www.theverge.com/report/879819/laurie-spiegel-is-celebrating-40-of-music-mouse-with-a-modern-revival",
      "description": "From Bell Labs to Macs, Laurie Spiegel has pushed musical boundaries. | Image: Irina Prosser / Eventide\t\n\nIn 1986, electronic music pioneer Laurie Spiegel created Music Mouse, a way for those with a Mac, Atari, or Amiga computer to dabble in algorithmic music creation. Music Mouse is deceptively simple: Notes are arranged on an XY grid, and you play it by moving a mouse around. Back in 1986, the computer mouse was still a relatively novel device. While it can trace its origins back to the late '60s, it wasn't until the Macintosh 128K in 1984 that it started seeing widespread adoption.\nBy then Spiegel, was already an accomplished composer. Her 1980 album The Expanding Universe is generally considered among the greatest ambient records of all tim …\nRead the full story at The Verge.",
      "content": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"Laurie Spiegel on the streets of NYC.\" data-caption=\"From Bell Labs to Macs, Laurie Spiegel has pushed musical boundaries. | Image: Irina Prosser / Eventide\" data-portal-copyright=\"Image: Irina Prosser / Eventide\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/04-Laurie-Spiegel-by-Irina-Prosser.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tFrom Bell Labs to Macs, Laurie Spiegel has pushed musical boundaries. | Image: Irina Prosser / Eventide\t</figcaption>\n</figure>\n<p class=\"has-drop-cap has-text-align-none\">In 1986, electronic music pioneer Laurie Spiegel created <a href=\"https://youtu.be/D-mmEvGOopk\">Music Mouse</a>, a way for those with a Mac, Atari, or Amiga computer to dabble in algorithmic music creation. <a href=\"https://www.eventideaudio.com/software/music-mouse/\">Music Mouse</a> is deceptively simple: Notes are arranged on an XY grid, and you play it by moving a mouse around. Back in 1986, the computer mouse was still a relatively novel device. While it can trace its origins back to the late '60s, it wasn't until the <a href=\"https://en.wikipedia.org/wiki/Macintosh_128K\">Macintosh 128K</a> in 1984 that it started seeing widespread adoption.</p>\n<p class=\"has-text-align-none\">By then Spiegel, was already an accomplished composer. Her 1980 album <a href=\"https://lauriespiegel.bandcamp.com/album/the-expanding-universe?search_item_id%3D1696851893%26search_item_type%3Da%26search_match_part%3D%253F%26search_page_id%3D5139357610%26search_page_no%3D0%26search_rank%3D2=\"><em>The Expanding Universe</em></a> is generally considered among the <a href=\"https://pitchfork.com/features/lists-and-guides/9948-the-50-best-ambient-albums-of-all-time/\">greatest ambient</a> records of all tim …</p>\n<p><a href=\"https://www.theverge.com/report/879819/laurie-spiegel-is-celebrating-40-of-music-mouse-with-a-modern-revival\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
      "author": "Terrence O’Brien",
      "source": "The Verge AI",
      "sourceType": "news",
      "pubDate": "2026-02-17T13:00:00.000Z",
      "popularity": 0,
      "category": "ai-other"
    },
    {
      "title": "The Small English Town Swept Up in the Global AI Arms Race",
      "link": "https://www.wired.com/story/the-small-english-town-swept-up-in-the-global-ai-arms-race/",
      "description": "The residents of Potters Bar are working to protect the “greenbelt” of farms, forests, and meadows that surround London from the endless demand for AI infrastructure.",
      "content": "The residents of Potters Bar are working to protect the “greenbelt” of farms, forests, and meadows that surround London from the endless demand for AI infrastructure.",
      "author": "Joel Khalili",
      "source": "Wired AI",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 07:00:00 +0000",
      "popularity": 0,
      "category": "ai-hardware"
    },
    {
      "title": "When to Think Fast and Slow? AMOR: Entropy-Based Metacognitive Gate for Dynamic SSM-Attention Switching",
      "link": "https://arxiv.org/abs/2602.13215",
      "description": "arXiv:2602.13215v1 Announce Type: new \nAbstract: Transformers allocate uniform computation to every position, regardless of difficulty. State Space Models (SSMs) offer efficient alternatives but struggle with precise information retrieval over a long horizon. Inspired by dual-process theories of cognition (Kahneman, 2011), we propose AMOR (Adaptive Metacognitive Output Router), a hybrid architecture that dynamically engages sparse attention only when an SSM backbone is \"uncertain\"--as measured by prediction entropy. Compared to standard transformers, AMOR gains efficiency by projecting keys and values from SSM hidden states (Ghost KV), reusing the SSM's O(n) computation rather than requiring O(n^2) attention at every layer. On small-scale synthetic retrieval tasks, AMOR outperforms both SSM-only and transformer-only baselines, achieving perfect retrieval accuracy while engaging attention on only 22% of positions. We validate that prediction entropy reliably signals retrieval need, with a gap of 1.09 nats (nearly half the entropy range) between retrieval and local positions. Additionally, our approach provides interpretable adaptive computation, where routing decisions can be understood in information-theoretic terms.",
      "content": "arXiv:2602.13215v1 Announce Type: new \nAbstract: Transformers allocate uniform computation to every position, regardless of difficulty. State Space Models (SSMs) offer efficient alternatives but struggle with precise information retrieval over a long horizon. Inspired by dual-process theories of cognition (Kahneman, 2011), we propose AMOR (Adaptive Metacognitive Output Router), a hybrid architecture that dynamically engages sparse attention only when an SSM backbone is \"uncertain\"--as measured by prediction entropy. Compared to standard transformers, AMOR gains efficiency by projecting keys and values from SSM hidden states (Ghost KV), reusing the SSM's O(n) computation rather than requiring O(n^2) attention at every layer. On small-scale synthetic retrieval tasks, AMOR outperforms both SSM-only and transformer-only baselines, achieving perfect retrieval accuracy while engaging attention on only 22% of positions. We validate that prediction entropy reliably signals retrieval need, with a gap of 1.09 nats (nearly half the entropy range) between retrieval and local positions. Additionally, our approach provides interpretable adaptive computation, where routing decisions can be understood in information-theoretic terms.",
      "author": "Haoran Zheng",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "PlotChain: Deterministic Checkpointed Evaluation of Multimodal LLMs on Engineering Plot Reading",
      "link": "https://arxiv.org/abs/2602.13232",
      "description": "arXiv:2602.13232v1 Announce Type: new \nAbstract: We present PlotChain, a deterministic, generator-based benchmark for evaluating multimodal large language models (MLLMs) on engineering plot reading-recovering quantitative values from classic plots (e.g., Bode/FFT, step response, stress-strain, pump curves) rather than OCR-only extraction or free-form captioning. PlotChain contains 15 plot families with 450 rendered plots (30 per family), where every item is produced from known parameters and paired with exact ground truth computed directly from the generating process. A central contribution is checkpoint-based diagnostic evaluation: in addition to final targets, each item includes intermediate 'cp_' fields that isolate sub-skills (e.g., reading cutoff frequency or peak magnitude) and enable failure localization within a plot family. We evaluate four state-of-the-art MLLMs under a standardized, deterministic protocol (temperature = 0 and a strict JSON-only numeric output schema) and score predictions using per-field tolerances designed to reflect human plot-reading precision. Under the 'plotread' tolerance policy, the top models achieve 80.42% (Gemini 2.5 Pro), 79.84% (GPT-4.1), and 78.21% (Claude Sonnet 4.5) overall field-level pass rates, while GPT-4o trails at 61.59%. Despite strong performance on many families, frequency-domain tasks remain brittle: bandpass response stays low (<= 23%), and FFT spectrum remains challenging. We release the generator, dataset, raw model outputs, scoring code, and manifests with checksums to support fully reproducible runs and retrospective rescoring under alternative tolerance policies.",
      "content": "arXiv:2602.13232v1 Announce Type: new \nAbstract: We present PlotChain, a deterministic, generator-based benchmark for evaluating multimodal large language models (MLLMs) on engineering plot reading-recovering quantitative values from classic plots (e.g., Bode/FFT, step response, stress-strain, pump curves) rather than OCR-only extraction or free-form captioning. PlotChain contains 15 plot families with 450 rendered plots (30 per family), where every item is produced from known parameters and paired with exact ground truth computed directly from the generating process. A central contribution is checkpoint-based diagnostic evaluation: in addition to final targets, each item includes intermediate 'cp_' fields that isolate sub-skills (e.g., reading cutoff frequency or peak magnitude) and enable failure localization within a plot family. We evaluate four state-of-the-art MLLMs under a standardized, deterministic protocol (temperature = 0 and a strict JSON-only numeric output schema) and score predictions using per-field tolerances designed to reflect human plot-reading precision. Under the 'plotread' tolerance policy, the top models achieve 80.42% (Gemini 2.5 Pro), 79.84% (GPT-4.1), and 78.21% (Claude Sonnet 4.5) overall field-level pass rates, while GPT-4o trails at 61.59%. Despite strong performance on many families, frequency-domain tasks remain brittle: bandpass response stays low (<= 23%), and FFT spectrum remains challenging. We release the generator, dataset, raw model outputs, scoring code, and manifests with checksums to support fully reproducible runs and retrospective rescoring under alternative tolerance policies.",
      "author": "Mayank Ravishankara",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "Accuracy Standards for AI at Work vs. Personal Life: Evidence from an Online Survey",
      "link": "https://arxiv.org/abs/2602.13283",
      "description": "arXiv:2602.13283v1 Announce Type: new \nAbstract: We study how people trade off accuracy when using AI-powered tools in professional versus personal contexts for adoption purposes, the determinants of those trade-offs, and how users cope when AI/apps are unavailable. Because modern AI systems (especially generative models) can produce acceptable but non-identical outputs, we define \"accuracy\" as context-specific reliability: the degree to which an output aligns with the user's intent within a tolerance threshold that depends on stakes and the cost of correction. In an online survey (N=300), among respondents with both accuracy items (N=170), the share requiring high accuracy (top-box) is 24.1% at work vs. 8.8% in personal life (+15.3 pp; z=6.29, p<0.001). The gap remains large under a broader top-two-box definition (67.0% vs. 32.9%) and on the full 1-5 ordinal scale (mean 3.86 vs. 3.08). Heavy app use and experience patterns correlate with stricter work standards (H2). When tools are unavailable (H3), respondents report more disruption in personal routines than at work (34.1% vs. 15.3%, p<0.01). We keep the main text focused on these substantive results and place test taxonomy and power derivations in a technical appendix.",
      "content": "arXiv:2602.13283v1 Announce Type: new \nAbstract: We study how people trade off accuracy when using AI-powered tools in professional versus personal contexts for adoption purposes, the determinants of those trade-offs, and how users cope when AI/apps are unavailable. Because modern AI systems (especially generative models) can produce acceptable but non-identical outputs, we define \"accuracy\" as context-specific reliability: the degree to which an output aligns with the user's intent within a tolerance threshold that depends on stakes and the cost of correction. In an online survey (N=300), among respondents with both accuracy items (N=170), the share requiring high accuracy (top-box) is 24.1% at work vs. 8.8% in personal life (+15.3 pp; z=6.29, p<0.001). The gap remains large under a broader top-two-box definition (67.0% vs. 32.9%) and on the full 1-5 ordinal scale (mean 3.86 vs. 3.08). Heavy app use and experience patterns correlate with stricter work standards (H2). When tools are unavailable (H3), respondents report more disruption in personal routines than at work (34.1% vs. 15.3%, p<0.01). We keep the main text focused on these substantive results and place test taxonomy and power derivations in a technical appendix.",
      "author": "Gaston Besanson, Federico Todeschini",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "On-Policy Supervised Fine-Tuning for Efficient Reasoning",
      "link": "https://arxiv.org/abs/2602.13407",
      "description": "arXiv:2602.13407v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) are commonly trained with reinforcement learning (RL) to explore long chain-of-thought reasoning, achieving strong performance at high computational cost. Recent methods add multi-reward objectives to jointly optimize correctness and brevity, but these complex extensions often destabilize training and yield suboptimal trade-offs. We revisit this objective and challenge the necessity of such complexity. Through principled analysis, we identify fundamental misalignments in this paradigm: KL regularization loses its intended role when correctness and length are directly verifiable, and group-wise normalization becomes ambiguous under multiple reward signals. By removing these two items and simplifying the reward to a truncation-based length penalty, we show that the optimization problem reduces to supervised fine-tuning on self-generated data filtered for both correctness and conciseness. We term this simplified training strategy on-policy SFT. Despite its simplicity, on-policy SFT consistently defines the accuracy-efficiency Pareto frontier. It reduces CoT length by up to 80 while maintaining original accuracy, surpassing more complex RL-based methods across five benchmarks. Furthermore, it significantly enhances training efficiency, reducing GPU memory usage by 50% and accelerating convergence by 70%. Our code is available at https://github.com/EIT-NLP/On-Policy-SFT.",
      "content": "arXiv:2602.13407v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) are commonly trained with reinforcement learning (RL) to explore long chain-of-thought reasoning, achieving strong performance at high computational cost. Recent methods add multi-reward objectives to jointly optimize correctness and brevity, but these complex extensions often destabilize training and yield suboptimal trade-offs. We revisit this objective and challenge the necessity of such complexity. Through principled analysis, we identify fundamental misalignments in this paradigm: KL regularization loses its intended role when correctness and length are directly verifiable, and group-wise normalization becomes ambiguous under multiple reward signals. By removing these two items and simplifying the reward to a truncation-based length penalty, we show that the optimization problem reduces to supervised fine-tuning on self-generated data filtered for both correctness and conciseness. We term this simplified training strategy on-policy SFT. Despite its simplicity, on-policy SFT consistently defines the accuracy-efficiency Pareto frontier. It reduces CoT length by up to 80 while maintaining original accuracy, surpassing more complex RL-based methods across five benchmarks. Furthermore, it significantly enhances training efficiency, reducing GPU memory usage by 50% and accelerating convergence by 70%. Our code is available at https://github.com/EIT-NLP/On-Policy-SFT.",
      "author": "Anhao Zhao, Ziyang Chen, Junlong Tong, Yingqi Fan, Fanghua Ye, Shuhao Li, Yunpu Ma, Wenjie Li, Xiaoyu Shen",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-chip"
    },
    {
      "title": "BotzoneBench: Scalable LLM Evaluation via Graded AI Anchors",
      "link": "https://arxiv.org/abs/2602.13214",
      "description": "arXiv:2602.13214v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly deployed in interactive environments requiring strategic decision-making, yet systematic evaluation of these capabilities remains challenging. Existing benchmarks for LLMs primarily assess static reasoning through isolated tasks and fail to capture dynamic strategic abilities. Recent game-based evaluations employ LLM-vs-LLM tournaments that produce relative rankings dependent on transient model pools, incurring quadratic computational costs and lacking stable performance anchors for longitudinal tracking. The central challenge is establishing a scalable evaluation framework that measures LLM strategic reasoning against consistent, interpretable standards rather than volatile peer models. Here we show that anchoring LLM evaluation to fixed hierarchies of skill-calibrated game Artificial Intelligence (AI) enables linear-time absolute skill measurement with stable cross-temporal interpretability. Built on the Botzone platform's established competitive infrastructure, our BotzoneBench evaluates LLMs across eight diverse games spanning deterministic perfect-information board games to stochastic imperfect-information card games. Through systematic assessment of 177,047 state-action pairs from five flagship models, we reveal significant performance disparities and identify distinct strategic behaviors, with top-performing models achieving proficiency comparable to mid-to-high-tier specialized game AI in multiple domains. This anchored evaluation paradigm generalizes beyond games to any domain with well-defined skill hierarchies, establishing a scalable and reusable framework for assessing interactive AI capabilities.",
      "content": "arXiv:2602.13214v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly deployed in interactive environments requiring strategic decision-making, yet systematic evaluation of these capabilities remains challenging. Existing benchmarks for LLMs primarily assess static reasoning through isolated tasks and fail to capture dynamic strategic abilities. Recent game-based evaluations employ LLM-vs-LLM tournaments that produce relative rankings dependent on transient model pools, incurring quadratic computational costs and lacking stable performance anchors for longitudinal tracking. The central challenge is establishing a scalable evaluation framework that measures LLM strategic reasoning against consistent, interpretable standards rather than volatile peer models. Here we show that anchoring LLM evaluation to fixed hierarchies of skill-calibrated game Artificial Intelligence (AI) enables linear-time absolute skill measurement with stable cross-temporal interpretability. Built on the Botzone platform's established competitive infrastructure, our BotzoneBench evaluates LLMs across eight diverse games spanning deterministic perfect-information board games to stochastic imperfect-information card games. Through systematic assessment of 177,047 state-action pairs from five flagship models, we reveal significant performance disparities and identify distinct strategic behaviors, with top-performing models achieving proficiency comparable to mid-to-high-tier specialized game AI in multiple domains. This anchored evaluation paradigm generalizes beyond games to any domain with well-defined skill hierarchies, establishing a scalable and reusable framework for assessing interactive AI capabilities.",
      "author": "Lingfeng Li, Yunlong Lu, Yuefei Zhang, Jingyu Yao, Yixin Zhu, KeYuan Cheng, Yongyi Wang, Qirui Zheng, Xionghui Yang, Wenxin Li",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-hardware"
    },
    {
      "title": "MAPLE: A Sub-Agent Architecture for Memory, Learning, and Personalization in Agentic AI Systems",
      "link": "https://arxiv.org/abs/2602.13258",
      "description": "arXiv:2602.13258v1 Announce Type: new \nAbstract: Large language model (LLM) agents have emerged as powerful tools for complex tasks, yet their ability to adapt to individual users remains fundamentally limited. We argue this limitation stems from a critical architectural conflation: current systems treat memory, learning, and personalization as a unified capability rather than three distinct mechanisms requiring different infrastructure, operating on different timescales, and benefiting from independent optimization. We propose MAPLE (Memory-Adaptive Personalized LEarning), a principled decomposition where Memory handles storage and retrieval infrastructure; Learning extracts intelligence from accumulated interactions asynchronously; and Personalization applies learned knowledge in real-time within finite context budgets. Each component operates as a dedicated sub-agent with specialized tooling and well-defined interfaces. Experimental evaluation on the MAPLE-Personas benchmark demonstrates that our decomposition achieves a 14.6% improvement in personalization score compared to a stateless baseline (p < 0.01, Cohen's d = 0.95) and increases trait incorporation rate from 45% to 75% -- enabling agents that genuinely learn and adapt.",
      "content": "arXiv:2602.13258v1 Announce Type: new \nAbstract: Large language model (LLM) agents have emerged as powerful tools for complex tasks, yet their ability to adapt to individual users remains fundamentally limited. We argue this limitation stems from a critical architectural conflation: current systems treat memory, learning, and personalization as a unified capability rather than three distinct mechanisms requiring different infrastructure, operating on different timescales, and benefiting from independent optimization. We propose MAPLE (Memory-Adaptive Personalized LEarning), a principled decomposition where Memory handles storage and retrieval infrastructure; Learning extracts intelligence from accumulated interactions asynchronously; and Personalization applies learned knowledge in real-time within finite context budgets. Each component operates as a dedicated sub-agent with specialized tooling and well-defined interfaces. Experimental evaluation on the MAPLE-Personas benchmark demonstrates that our decomposition achieves a 14.6% improvement in personalization score compared to a stateless baseline (p < 0.01, Cohen's d = 0.95) and increases trait incorporation rate from 45% to 75% -- enabling agents that genuinely learn and adapt.",
      "author": "Deepak Babu Piskala",
      "source": "arXiv AI Papers",
      "sourceType": "news",
      "pubDate": "Tue, 17 Feb 2026 00:00:00 -0500",
      "popularity": 0,
      "category": "ai-hardware"
    }
  ]
}